{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41b14719-2822-4d37-8795-3af22f5e35c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ques. What is Partition?**\n",
    "\n",
    "_Ans. To allow executors to work in parallel, spark breaks down the data into chunks called **Partitions**._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ca4866d-5906-4bdf-9d05-1cc3ada998a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ques. What is Transformation?**\n",
    "\n",
    "_Ans. The instruction or code to modify and transform data is known as Transformation_\n",
    "\n",
    "_Eg. select, where, groupBy etc._\n",
    "\n",
    "_Transformation helps in building the logical plan._\n",
    "\n",
    "_Types of Transformations:_\n",
    "- _Narrow Transformation: one input data partition contributes to one output data partition_\n",
    "- _Wide Transformation: one input data partition contributes to more than one output data partiton, this lead to **shuffle**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "842088e2-c1de-4083-8920-e402c15b20a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ques. What is Actions?**\n",
    "\n",
    "_Ans. To trigger the execution, we need to call an Action_\n",
    "\n",
    "_This basically executes the plan created by Transformation_\n",
    "\n",
    "_Types of Actions:_\n",
    "- _View data in console_\n",
    "- _Collect data in native language_\n",
    "- _Write data to output data sources_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09481d3f-2f76-47fb-938a-7915c922721e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Spark prefers Lazy Evaluation**\n",
    "\n",
    "_Spark will wait till last moment to execute the graph of computation._\n",
    "\n",
    "_This allows Spark to optimize, plan and use the resources properly for execution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acc7941e-b488-44b3-90cf-9b569730cf14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Ques. What is Spark Session?**\n",
    "\n",
    "_Ans._\n",
    "\n",
    "- _The Driver Process is known as Spark Session_\n",
    "- _It is the entry point for a Spark execution_\n",
    "- _The Spark Session instance executes the code in the cluster_\n",
    "- _And the relation is one-to-one, that is, for 1 Spark Application we will have 1 Spark Session Instance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d905f55-92a6-4f34-aba8-4eb95bf5c9ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark Transformation and Actions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
